# 레디스

- Remote dictionary server
  - In-Memory Data Structure Store
  - 프로세스에 존재
- 지원하는 자료구조
  - String
  - set
  - sorted-set
  - hashes
  - list
  - hyperloglog
  - bitmap
  - geospatial idex
  - Stream



### 1. 캐쉬란?

- 나중에 요청올 결과를 미치 저장해주었다가 빠르게 서비스를 해주는 것을 의미
- 속도 ( 용량은 반대 )
  - CPU 레지스트리 > 캐쉬 > 메모리 > 디스크
- Look aside Cache ( 제일 많이 사용 )
  - DB 가기전 미리 캐쉬를 확인
  - 캐쉬에 데이터가 없으면 DB에서 확인
    - 그것을 캐쉬에 저장하고 결과를 클라이언트로 전송
- Write Back
  - 쓰기가 가장 빈번할 경우 먼저 캐쉬에 저장
    - 인메모리 특성상 읽기 / 쓰기가 빠릅니다.
  - 특정 시점마다 DB에 다시 저장
    - 500개의 데이터를 하나식 쿼리날리는 것보다 500개의 데이터를 한번에 Insert하는 것이 훨씬 빠르다.
  - 단점
    - 장애가 발생하면 데이터 유실이 생길 수 있습니다.
  - 사용방법
    - 로그를 DB에 저장할 때 많이 사용합니다.



## 2. 왜 Collection이 중요한가?

- 레디스는 Collection을 제공합니다.
- 그래서 개발의 편의성과 개발의 난이도가 편해집니다.
  - 랭킹 서버를 직접 구현한다면?
    - DB 유저의 Score를 저장하고 oder by로 정렬 후 읽어오기
    - 개수가 많아지면 성능이 저하됩니다.
    - 하지만 레디스의 Sorted Set을 이용한다면?
      - 쉽게 랭킹을 구현할 수 있습니다.
  - 친구 리스트를 관리한다면?
    - 친구 리스트를 Key / Value 형태로 저장해야 한다면?
      - 트랜잭션에서 순서가 뒤바뀌면서 유실될 수 있습니다.
      - 레디스는 자료구조가 Atomic이기 때문에 해당 Race Condition 문제를 피할 수 있습니다.
      - Race Condition
        - 여러 개의 쓰래드가 경합함녀서 Context Switching이 발생하다보면 원하는 결과가 발생하지 않을 수도 있습니다.
        - 레디스는 싱글 스래드 및 아토믹한 성질을 통해 Critical Section에 대한 동기화를 제공합니다.
          - Critical Section: 동시에 프로스세 여러개가 접근하지 못하는 영역을 의미
          - 즉 어려 트랜잭션들이 Read/Write를 동기화해주는 기본적인 구현이 되어 있습니다.
- 즉 외부 Collection을 잘 이용하면 개발 시간을 단축할 수 있고 비즈니스 로직에 집중할 수 있습니다.



## 3. 레디스 사용처?

- Remote Data Store
  - 여러 대의 서버에서 같은 데이터를 보고 싶을  사용
  - 만약 서버 1대에서 사용하면 전역 변수를 사용하면 되는거 아닌가?
    - 레디스 자체가 Atomic 하고 싱슬 스레드 이기 때문에 이슈가 덜합니다.
      - 그래도 조심은 해야 합니다.
  - 인증 토큰 저장( String / Hash )
  - Ranking 보드로 사용( Sorted Set )
  - 유저 API Limit



## 4. Redis Collections

- String
  - Set <key> <value>
  - Get <key>
  - 그럼 Key를 어떻게 정의해야 할까?
    - 대부분 prefix를 사용
      - Set token:1234 abcd
      - Get token:1234
  - 멀티 Key
    - mset <kety1> <value1> <kety2> <value2>...
    - Get <key1> <key2> ... 
- List
  - Array로 구현되어 있기 때문에 중간에 데이터 삽입에는 최악
  - 앞 / 뒤에서 자료를 넣을 수 있습니다.
  - Lpush <key> <A>
  - Rpush <key> <B>
  - LPOP <key>
  - RPOP <key>
  - 배열이 비어있을 때
    - BLPOP <key>
    - 누가 데이터를 push 하기전까지 대기
- Set
  - 중복 데이터 제거
  - SADD <key> <value>
    - vaule가 이미 존재하면 추가되지 않습니다.
  - SMEMBERS <key>
    - 모든 value를 가져옵니다.
  - SISMEMBERS <key> <value>
    - value가 존재하면 1, 없으면 0
- Sorted Set
  - Set은 순서가 없지만 이 구조는 순서를 보장할 수 있다. 
    - Score 기준으로 정렬
  - ZADD <Key> <Score> <Value>
    - value가 이미 key에 있으면 해당 score로 변경됩니다.
  - ZRANGE <Key> <StartIndex> <EndIndex>
    - 해당 Index 범위 값을 모두 돌려줍니다.
    - Zrange key 0 -1
      - 모든 범위를 가져옵니다.
    - Zrange key 50 70
    - Zrevrange key 50 70
      - 거꾸로 가져오기 ( desc )
  - 랭킹 보드에서 자주 사용합니다.
  - Score는 double 타입이기 때문에 값이 정확히지 않을 수도 있습니다.
    - js에서 long으로 표현할 수 없는 숫자가 있는데 이것을 문자열로 보내는 것과 같은 현상
- Hash
  - Hmset <key> <subkey1> <value1> <subkey2> <value2>
  - Hgetall <key>
    - 해당 key의 모든 subkey와 value를 가져옵니다.
  - Hget <key> <subkey>
  - Hmget <key> <subkey1> <subkey2> ....

- Collection 주의사항
  - 하나의 컬렉션에 너무 많은 아이템들을 담으면 안전하지 않습니다.
    - 10000개 이하 수준으로 유지하는게 좋습니다.
  - Expire는 Collection의 item 개별로 걸리지 않고 전체 Collection에 대해서만 걸립니다.
    - Expire는 TTL를 걸어서 item을 지우는 기능
    - 즉 모두 제거가 되니까 조심해야 하고 메모리를 더 소모하는 것입니다.



## 5. 레디스 운영

- 메모리 관리를 잘해야 합니다.

  - Physical Memory 이상의 사용하면 문제가 발생합니다.

  - Swap이 있으면 Swap을 사용하므로 해당 메모리 Page 접근시 마다 늦어지게 됩니다.

    - Swap: 메모리를 다시 디스크에 저장하고 필요할 때 로딩시켜서 재사용
      - 프로세스를 메모리에 올릴 때 전체 프로세스를 올리지 않고 일부만 올려서 메모리에 사용합니다.
      - 덜 쓰이는 프로세스는 디스크에 저장했따가 필요할 때 메모리로 올려서 사용하는 방식을 선택하고 있습니다.
    - Swap이 한번이라도 실행된 메모리 페이지는 계속 Swap이 일어나며 그 key를 접근할 때마다 디스크를 읽고 쓰게되면서 성능이 저하됩니다.
    - Swap이 없다면 죽어버립니다.

  - Maxmemory를 설정하더라도 이보다 더 사용할 가능성이 큽니다.

    - Maxmemory 옵션: 해당 메모리보다 더 사용하게 된다면 레디스가 알아서 데이터를 랜덤하게 지우거나 Expire 목록에 있는 것을 지워서 메모리를 확보해서 사용하는 옵션 

    - 메모리 관련 내부 알고리즘(jemlloc)이 존재하지만 레디스는 정확히 자기가 사용하는 메모리를 유추하기 힘듭니다.

      - 메모리 파편화 현상
        - 메모리를 할당 받고 해제하는 과정에서 부분 부분 비어있는 공간이 생기는데 이 과정 속에서 커다란 프로세스를 할당할 때 피지컬 메모리에서 사용하지 못하는 부분이 생깁니다.
        - 그래서 실제 사용하는 것 보다 더 많은 메모리를 사용하는 것으로 컴퓨터가 인식하고 프로세스가 죽는 현상이 발생합니다.

      - 4.x 버전 부터 메모리 파편화가 줄도록 jemlloc에 힌트를 주는 기능이 추가됬으나 jemalloc 버전에 따라 또 다르게 동작할 수 있습니다.
      - 3.x 버전의 경우는 실제 사용 메모리는  2GB로 보고되지만 11GB의 RSS를 사용하는 경우가 자주 발생합니다.
        - RSS: Resident Set Size이며 해당 프로세스에 할당되고 RAM에있는 메모리 양을 표시하는 데 사용
      - 다양한 사이즈를 가지는 데이터 보다 유사한 크기의 데이터를 가지는 경우가 더 유리합니다.

  - 많은 업체가 현재 메모리를 사용해서 Swap을 쓰고 있다는 것을 모르는 경우가 많습니다.

    - 그래서 모니터링을 도입해야 합니다.

  - 큰 메모리를 사용하는 인스턴스보다 **적은 메모리를 사용하는 인스턴스 여러 개가 더 안전**합니다.

    - 포크로 인해 메모리 복사(1.5~2배)가 일어날 때 인스턴스가 분산되어 있으면 문제가 일으킬 확률이 줄어듭니다.

  - 메모리가 부족할 때?

    - 좀 더 메모리가 많은 장비로 마이그레이션을 해야 합니다.
    - 또 메모리를 빡빡하게 사용하면 문제가 발생하기도 합니다.
      - 그래서 보통 70% 정도 사용하고 있을 때 이전해야 합니다.
    - 불필요한 데이터를 제거해서 개선합니다.
    - 기본적으로 Collection들은 이러한 자료구조를 사용합니다.
      - Hash: HashTable을 하나 더 사용합니다.
      - Sorted Set: Skiplist와 HashTable을 이용합니다.
      - Set: HashTable을 사용합니다.
      - 이런 자료구조들은 메모리들을 많이 사용하니 그래서 적절하게 사용해야 합니다.
    - Ziplist를 이용하면 좋습니다.
      - Collection을 사용할때 쓰는 자료구조말고 Ziplist로 사용하도록 설정 변경이 가능합니다.
        - Ziplist는 특정 자료구조를 안쓰고 선형으로 처리
      - 속도는 조금 떨어지지만 메모리 효율을 높일 수 있습니다.
        - 몇개의 개수까지만  Ziplist 사용 설정
      - 구조
        - In-Memory 특성 상 적은 개수면 선형 탐색을 하더라도 엄청 빠릅니다.
        - ex) hash-max-ziplist-entries ( 개수 몇개까지  zlplist 사용 )

- O(N) 관련 명령어는 주의해야 합니다. 

  - 레디스는 싱글 스레드 기반 입니다.
  - 즉 동시에 동시에 처리할 수 있는 명령은 한번에 1개 입니다.
    - 참고로 단순한 get / set은 초당 1만 TPS이상 가능( CPU 속도 영향 )
  - 긴 시간이 필요한 명령을 수행하면 안됩니다.
    - KEYS: 모든 키를 수행하는 명령어
      - scan 명령어로 대체가 가능하빈다.
        - 짧게 여러번 명령어를 통해 가져오기
    - FLUSHALL, FLUSHDB: 모든 데이터 제거
    - Delete Collections: 컬렉션 내부에 있는 데이터 제거
    - Get All Collections: 컬랙션 내부의 데이터 모두 가져오기
      - 큰 Collection을 작은 여러개의 Collection으로 나눠서 관리해야 합니다.
      - 하나당 몇천개 안으로 저장하는게 제일 좋습니다.

- Replication

  - A라는 서버의 데이터를  B서버도 다같이 들고 있게 하는 것
  - Async Replication
    - Replication Lag가 발생할 수 있습니다.
    - 한마디로 A서버에서 데이터가 변경되면 B서버도 변경하라고 요청을 하는데 그 순간 데이터가 다르게 됩니다.
    - 그 틈사이에 데이터를 사용하게 되면 다른 데이터가 사용될 수 있습니다.
    - DBMS로 보면 statement replication과 유사합니다.
      - 즉 replication간에 쿼리로 전송하다는 의미인데 now()라는 쿼리를 사용하면 서로 다른 날짜가 기록되게 됩니다.
  - 설정 과정
    - Secondary에 replica of / slaveof 명령으로 Master의 주소와 포트를 연결
      - 내부적으로 Secondary는 Primary에 sync 명령 전달
      - 이 때 Primary는 현재 메모리 상태를 저장하기 위해 Fork를 진행
      - Fork 한 프로세서는 현재 메모리 정보를 disk에 dump
        - Fork: 프로세스를 동일하게 메모리상에서 복제하는 방식
        - 이 과정에서 메모리가 가득 차있으면 제대로 메모리가 복사되지 않고 죽어버리는 현상 발생
      - 해당 정보를 secondary에 전달
      - Fork 이후의 데이터를 secondeary에 계속 전달
  - 주의점
    - Replication과정에서 fork가 발생함으로 메모리 부족이 발생할 수 있습니다.
    - 많은 레디스가 Replica를 가지고 있으면 네트워크 이슈나 사람의 작업으로 동시에 replication이 재시도 되로록 하면 문제가 발생할 수 있습니다.

## 권장 설정

- Maxclient 설정 50000 ( 많이 높이기 )
  - Maxclient 만틈만 네트워크로 접속할 수 있습니다.

- RDB / AOF 설정 off
- 특정 commands disable
  - keys
  - Asw의 ElasticCache는 이미 하고 있습니다.
- 전체 장애의 90% 이상이 keys와 save 설정을 사용해서 발생합니다.
  - save 설정: 1분안에 key가 만개가 바뀌면 dump해라! 라는 디폴트 설정 => 메모리를 계속 사용해서 저하 발생
- 적절하게 ziplist를 설정합니다.



## Redis 데이터 분산

- 데이터의 특성에 따라서 선택할 수 있는 방법이 달라집니다.
  - Application 레벨에서 나누는 방법 
    - Consistent Hashing
      - 서버_1: modular_0
      - 서버_2: modular_1
        - Id_1000 =>1000/2 = 0번 으로
        - Id_5001 => 5000/2 = 1번 으로
        - Id_10002 => 10002/2 = 0번으로
        - Id_3003 => 3003/2 = 1번으로
      - 즉 데이터가 들어오면 나눠지게 됩니다.
      - 하지만 서버가 꽉차게 되면?
        - 서버 증설을 통해 서버_3: modular_2를 도입합니다.
        - 그럼 다른 데이터들은 이동이 생깁니다 => 안좋은 현상
        - 한마디로 이 방식은 장애 대응에 취약한 방식 => 이것을 **Consistent Hashing**로 해결
      - 갹 key값을 바탕으로 똑같이  Hash를 해서 나온 값을 바탕으로 데이터가 서버를 선택해 들어가게 됩니다.
        - 중간에 서버가 사라지면 나머지 데이터는 변동이 없고 사라진 서버의 데이터만 이동하게 됩니다.
        - 다시 서버가 생기게 되면 기존에 관련된 데이터들만 이동하게 됩니다.
        - 즉 key의 해쉬값은 일정하게 나오기 때문에 평균 4/1 데이터만 이동하게 됩니다.
    - Sharding
      - Range
        - 그냥 특정 Range를 정의하고 해당  Range에 속하면 거기에 정하는 것입니다.
          - 1~1000 /.1001~2000 / 2001~3000
          - key 500은 첫번째 서버에 들어가면 됩니다!
        - 하지만 서버의 상황에 따라서 데이터 불균형 현상이 발생합니다.
      - Modular 방법에서 규칙을 이용하면 효율을 높일 수 있습니다.
        - 2배로 서버를 확장할 경우 규칙이 생겨 데이터의 이동이 규칙성 있게 이동하게 됩니다.
        - 하지만 서버가 커질 수록 확장하는 규모가 점점 커지는게 단점입니다.
      - Indexed
        - 해당  key가 어디로 가야할지 관리하는 서버가 따로 존재
        - 하지만 이 서버의 장애가 발생한다면 또 다른 이슈 포인트가 생기는 것
  - Redis Cluster로 나누는 방법
    - Hash 기반으로 Slot 16384로 구분합니다
      - CRC16 해쉬 알고리즘 사용
      - Slot 16384를 사용해도 특정 서버 다른 곳으로 임의로 데이터를 보낼 수 있습니다.
    - Primary #1 --- Secondary #1에서 Primary가 죽으면 Secondary가 Primary로 자동 승격합니다.
    - 단점
      - 메모리 사용량이 더 많습니다.
      - Migration 자체는 관리자가 시점을 결정해야 합니다.
      - 라이브러리 구현이 필요합니다.

## Redis Failover 

- **Failover**란 장애극복을 위해 예비 운용환경으로 자동전환하는 기능입니다.
- Coordinator 기반 Failover
  - Zookeeper, etcd, consul 등의 Coordinator를 사용합니다.
  - Coordinator는 해당 정보를 저장해서 그 값을 사용하다가 ( 지금 레디스 1번을 사용해) 레디스 1번이 죽이면 Helath Checker가 감지하고 레디스 2번을 primary로 승격하고 Coordinator에게 현재 레디스는 2번이야라고 업데이트를 시켜줍니다.
  - Coordinator는 다시 API Server에 레디스가 변경되었다고 알려줍니다.
- VIP/DNS 기반  Failover
  - VIP
    - 레디스는 가상 아이피를 할당해서 API Server가 특정 아이피로만 접속하도록 구현
    - 만약 레디스 1번이 죽으면 Helath Checker가 레디스 2번을 Primary로 승격시키고 다시 VIP를 레디스 2번으로 연결해줍니다.
  - DNS
    - VIP와 동일하게 작동합니다.
    - VIP 대신 DNS를 활용합니다.
  - 장점
    - 클라이언트의 추가적인 구현이 필요 없습니다.
  - 단점
    - VIP기반은 외부로 서비스를 제공해야 하는 서비스 업자에 유리 합니다.
    - DNS 기반은  DNS Cache TTL를 관리해야 합니다.
- Redis Cluster의 사용



## 모니터링

- Redis Info를 통한 정보
  - RSS
    - 피지컬 메모리를 얼마만큼 사용하고 있는가?
  - Used Memory
  - Connection 수
  - 초당 처리 요청 수
- System
  - CPU
  - DISK
  - Network rx/tx
- CPU가 100%일 경우
  - 처리량이 많으면 좀 더 성능이 높은 CPU로 업그레이드 해야 합니다.
  - O(n) 계열의 특정 명령이 맣은 경우
    - Monitor 명령을 통해 특정 패턴을 파악하는 것이 필요합니다.
    - Monitor를 잘못쓰면 부하로 해당 서버에 더 큰 문제를 일으킬 수 있으니 짧게 써야 합니다.



## 결론

- 기본적으로 레디스는 좋은 툴이긴 하지만 메모리를 빡빡하게 사용할 경우 관리하기가 어려워질 수 있습니다.
- Client-output-buffer-limit 설정을 크게 잡아야 합니다.
  - 이 값이 낮을 경우 커넥션이 증가하게 되면 끊어버리게 됩니다.
- Cache 일 경우에는 문제가 적게 발생합니다.
  - DB 부하가 더 중요!
- Persistent Store의 경우
  - 절대 지워지면 안되는 데이터일 경우 관리가 더 필요해집니다.
  - 거의  Primary/Secondary 구조로 구성이 필요합니다.
  - 메모리를 절대로 빡빡하게 사용하면 안됩니다.
    - 정기적인 마이그레이션이 필요합니다.
    - 가능하면 자동화 툴을 만들어서 사용해야 합니다.
  - RDB/AOF가 필요하면 Secondery에서만 구동해야 합니다.



## 참고 링크

- https://www.youtube.com/watch?v=mPB2CZiAkKM
- https://velog.io/@hyeondev/Redis-%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C